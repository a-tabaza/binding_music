{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dict(list_of_dict):\n",
    "    transformed_embedding = {}\n",
    "    for dictionary in list_of_dict:\n",
    "        transformed_embedding[dictionary['id']] = dictionary['embedding']\n",
    "\n",
    "    return transformed_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/fairouz/fairouz_conf/fairouz/notebooks\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = json.load(open('/workspace/fairouz/fairouz_conf/fairouz/tracks_contextualized.json'))\n",
    "track_ids = list(tracks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embeddings = json.load(open('/workspace/fairouz/fairouz_conf/fairouz/embeddings/audio/song_audio_vggish_embeddings.json'))\n",
    "graph_embeddings = json.load(open('/workspace/fairouz/fairouz_conf/fairouz/embeddings/graph/karate_club/song_nodes_RandNE_embedding.json'))\n",
    "image_embeddings = json.load(open('/workspace/fairouz/fairouz_conf/fairouz/embeddings/image/album_covers_openclip_embeddings.json'))\n",
    "text_embeddings = json.load(open('/workspace/fairouz/fairouz_conf/fairouz/embeddings/lyrics/song_lyrics_mxbai_embeddings.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embeddings_dict = transform_dict(audio_embeddings)\n",
    "graph_embeddings_dict = transform_dict(graph_embeddings)\n",
    "image_embeddings_dict = transform_dict(image_embeddings)\n",
    "text_embeddings_dict = transform_dict(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.array([np.array(audio[\"embedding\"]) for audio in audio_embeddings]).astype('float32')\n",
    "g_array = np.array([np.array(graph[\"embedding\"]) for graph in graph_embeddings]).astype('float32')\n",
    "i_array = np.array([np.array(image[\"embedding\"]) for image in image_embeddings]).astype('float32')\n",
    "t_array = np.array([np.array(text[\"embedding\"]) for text in text_embeddings]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((822, 128), (822, 128), (822, 512), (822, 1024))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_array.shape, g_array.shape, i_array.shape, t_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_index = faiss.IndexFlatL2(a_array.shape[1])\n",
    "audio_index.add(a_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_index = faiss.IndexFlatL2(g_array.shape[1])\n",
    "graph_index.add(g_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = faiss.IndexFlatL2(i_array.shape[1])\n",
    "image_index.add(i_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_index = faiss.IndexFlatL2(t_array.shape[1])\n",
    "text_index.add(t_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modality_embeddings(track_id):\n",
    "    audio_embedding = audio_embeddings_dict[track_id]\n",
    "    graph_embedding = graph_embeddings_dict[track_id]\n",
    "    image_embedding = image_embeddings_dict[track_id]\n",
    "    text_embedding = text_embeddings_dict[track_id]\n",
    "    return audio_embedding, graph_embedding, image_embedding, text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positives(track_id, k=10):\n",
    "    a_emb, g_emb, i_emb, t_emb = get_modality_embeddings(track_id)\n",
    "    modality_index = {\n",
    "        \"audio\": audio_index,\n",
    "        \"graph\": graph_index,\n",
    "        \"image\": image_index,\n",
    "        \"text\": text_index,\n",
    "    }\n",
    "    ids = {\n",
    "        \"audio\": audio_embeddings,\n",
    "        \"graph\": graph_embeddings,\n",
    "        \"image\": image_embeddings,\n",
    "        \"text\": text_embeddings,\n",
    "    }\n",
    "    modalities = {\"audio\": a_emb, \"graph\": g_emb, \"image\": i_emb, \"text\": t_emb}\n",
    "    positives = []\n",
    "    for modality, index in modality_index.items():\n",
    "        D, I = index.search(\n",
    "            np.array(modalities[modality]).reshape(1, -1).astype(\"float32\"), k\n",
    "        )\n",
    "        zipped_list = list(zip(D[0].tolist(), I[0].tolist()))\n",
    "        # positives.append({\"modality\": modality, \"positives\": [{\"distance\": D, \"index\": I} for D, I in zipped_list if D != 0]})\n",
    "        unique = [tuple for tuple in zipped_list if tuple[0] != 0]\n",
    "        positives.extend(ids[modality][unique[i][1]][\"id\"] for i in range(len(unique)))\n",
    "    return positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negatives(track_id):\n",
    "    ref_audio, ref_graph, ref_image, ref_text = get_modality_embeddings(track_id)\n",
    "    ids = np.random.choice(track_ids, 64)\n",
    "    a_d = []\n",
    "    g_d = []\n",
    "    i_d = []\n",
    "    t_d = []\n",
    "    for id in ids:\n",
    "        a_emb, g_emb, i_emb, t_emb = get_modality_embeddings(id)\n",
    "        a_d.append(np.dot(np.array(ref_audio), np.array(a_emb)))\n",
    "        g_d.append(np.dot(np.array(ref_graph), np.array(g_emb)))\n",
    "        i_d.append(np.dot(np.array(ref_image), np.array(i_emb)))\n",
    "        t_d.append(np.dot(np.array(ref_text), np.array(t_emb)))\n",
    "    audio_negatives = ids[np.argsort(a_d)[:10]]\n",
    "    graph_negatives = ids[np.argsort(g_d)[:10]]\n",
    "    image_negatives = ids[np.argsort(i_d)[:10]]\n",
    "    text_negatives = ids[np.argsort(t_d)[:10]]\n",
    "    return np.unique(np.concatenate([audio_negatives, graph_negatives, image_negatives, text_negatives])).tolist()\n",
    "    # return list(set([ids[np.argmin(a_d)], ids[np.argmin(g_d)], ids[np.argmin(i_d)], ids[np.argmin(t_d)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 822/822 [00:08<00:00, 94.37it/s] \n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for track_id in tqdm(track_ids):\n",
    "    data_dict[track_id] = {\"positives\": get_positives(track_id), \"negatives\": get_negatives(track_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data_dict, open('/workspace/fairouz/fairouz_conf/fairouz/positives_negatives_more_negatives.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
