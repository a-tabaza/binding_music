{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dict(list_of_dict):\n",
    "    transformed_embedding = {}\n",
    "    for dictionary in list_of_dict:\n",
    "        transformed_embedding[dictionary['id']] = dictionary['embedding']\n",
    "\n",
    "    return transformed_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = json.load(open('fairouz_conf/fairouz/tracks_contextualized.json'))\n",
    "track_ids = list(tracks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embeddings = json.load(open('fairouz_conf/fairouz/embeddings/audio/song_audio_vggish_embeddings.json'))\n",
    "graph_embeddings = json.load(open('fairouz_conf/fairouz/embeddings/graph/karate_club/song_nodes_RandNE_embedding.json'))\n",
    "image_embeddings = json.load(open('fairouz_conf/fairouz/embeddings/image/album_covers_openclip_embeddings.json'))\n",
    "text_embeddings = json.load(open('fairouz_conf/fairouz/embeddings/lyrics/song_lyrics_mxbai_embeddings.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embeddings_dict = transform_dict(audio_embeddings)\n",
    "graph_embeddings_dict = transform_dict(graph_embeddings)\n",
    "image_embeddings_dict = transform_dict(image_embeddings)\n",
    "text_embeddings_dict = transform_dict(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_array = np.array([np.array(audio[\"embedding\"]) for audio in audio_embeddings]).astype('float32')\n",
    "g_array = np.array([np.array(graph[\"embedding\"]) for graph in graph_embeddings]).astype('float32')\n",
    "i_array = np.array([np.array(image[\"embedding\"]) for image in image_embeddings]).astype('float32')\n",
    "t_array = np.array([np.array(text[\"embedding\"]) for text in text_embeddings]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((822, 128), (822, 128), (822, 512), (822, 1024))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_array.shape, g_array.shape, i_array.shape, t_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_index = faiss.IndexFlatL2(a_array.shape[1])\n",
    "audio_index.add(a_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_index = faiss.IndexFlatL2(g_array.shape[1])\n",
    "graph_index.add(g_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = faiss.IndexFlatL2(i_array.shape[1])\n",
    "image_index.add(i_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_index = faiss.IndexFlatL2(t_array.shape[1])\n",
    "text_index.add(t_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modality_embeddings(track_id):\n",
    "    audio_embedding = audio_embeddings_dict[track_id]\n",
    "    graph_embedding = graph_embeddings_dict[track_id]\n",
    "    image_embedding = image_embeddings_dict[track_id]\n",
    "    text_embedding = text_embeddings_dict[track_id]\n",
    "    return audio_embedding, graph_embedding, image_embedding, text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positives(track_id, k = 10):\n",
    "    a_emb, g_emb, i_emb, t_emb = get_modality_embeddings(track_id)\n",
    "    modality_index = {\"audio\": audio_index, \"graph\": graph_index, \"image\": image_index, \"text\": text_index}\n",
    "    ids = {\"audio\": audio_embeddings, \"graph\": graph_embeddings, \"image\": image_embeddings, \"text\": text_embeddings}\n",
    "    modalities = {\"audio\": a_emb, \"graph\": g_emb, \"image\": i_emb, \"text\": t_emb}\n",
    "    positives = []\n",
    "    for modality, index in modality_index.items():\n",
    "        D, I = index.search(np.array(modalities[modality]).reshape(1, -1).astype(\"float32\"), k)\n",
    "        zipped_list = list(zip(D[0].tolist(), I[0].tolist()))\n",
    "        # positives.append({\"modality\": modality, \"positives\": [{\"distance\": D, \"index\": I} for D, I in zipped_list if D != 0]})\n",
    "        unique = [tuple for tuple in zipped_list if tuple[0] != 0]\n",
    "        positives.append(ids[modality][unique[0][1]][\"id\"])\n",
    "    return positives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_negatives(track_id):\n",
    "    ref_audio, ref_graph, ref_image, ref_text = get_modality_embeddings(track_id)\n",
    "    ids = np.random.choice(track_ids, 40)\n",
    "    a_d = []\n",
    "    g_d = []\n",
    "    i_d = []\n",
    "    t_d = []\n",
    "    for id in ids:\n",
    "        a_emb, g_emb, i_emb, t_emb = get_modality_embeddings(id)\n",
    "        a_d.append(np.dot(np.array(ref_audio), np.array(a_emb)))\n",
    "        g_d.append(np.dot(np.array(ref_graph), np.array(g_emb)))\n",
    "        i_d.append(np.dot(np.array(ref_image), np.array(i_emb)))\n",
    "        t_d.append(np.dot(np.array(ref_text), np.array(t_emb)))\n",
    "\n",
    "        # a_d.append(faiss.pairwise_distances(np.array(ref_audio).reshape(1, -1).astype(\"float32\"), np.array(a_emb).reshape(1, -1).astype(\"float32\"))[0][0])\n",
    "        # g_d.append(faiss.pairwise_distances(np.array(ref_graph).reshape(1, -1).astype(\"float32\"), np.array(g_emb).reshape(1, -1).astype(\"float32\"))[0][0])\n",
    "        # i_d.append(faiss.pairwise_distances(np.array(ref_image).reshape(1, -1).astype(\"float32\"), np.array(i_emb).reshape(1, -1).astype(\"float32\"))[0][0])\n",
    "        # t_d.append(faiss.pairwise_distances(np.array(ref_text).reshape(1, -1).astype(\"float32\"), np.array(t_emb).reshape(1, -1).astype(\"float32\"))[0][0])\n",
    "    return list(set([ids[np.argmin(a_d)], ids[np.argmin(g_d)], ids[np.argmin(i_d)], ids[np.argmin(t_d)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(v1, v2):\n",
    "    return np.dot(np.array(v1), np.array(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ide3554d4190fd714e50345bd4906469af',\n",
       " 'id51f79510005a16836683c69d5ef37bc5',\n",
       " 'id28be4f9571336d8cbf23d18f7d7548b9',\n",
       " 'id92d80b2442fdeea5f83948c1bd6f16bf']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_positives(\"id264cf6a9f396151588583f76e5a51a6a\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 822/822 [00:05<00:00, 139.63it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "for track_id in tqdm(track_ids):\n",
    "    data_dict[track_id] = {\"positives\": get_positives(track_id, 50), \"negatives\": get_negatives(track_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data_dict, open('fairouz_conf/fairouz/positives_negatives.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
